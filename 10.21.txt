Name: Shun Zhang
EID: sz4554

== Comments and Questions ==

*. Learning and Using Models of Kicking Motions for Legged Robots 

Why don't they use a bird's-eye view camera? Then it's possible to
track the whole trajectory - including the moment when the ball is
kicked.  It would be interesting to build a belief over the position
of ball at any time, without observation, not restricted to length and
angle.

I didn't get the idea in Figure 5. What's the vertical axis?

They can use Kalman Filter to track the ball and determine the
distance and angle of the ball at t_delay more acurately. But as they
repeat the sampling many times and the noise should be un-biased, it's
okay.

*. Towards Autonomous Sensor and Actuator Model Induction on a Mobile
Robot

I think this is a very interesting idea and well-deserved for a
dissertation.

"Because the world state can be estimated from independent, redundant
sources of information, the robot can use this information to learn a
model of any given individual source" (page 5, line 1)
Is "redundant" here defined more than "complete"? If the environment
has nothing more than just complete information, will ASAMI still
work?

The exploration over state, action space is a non-trival task. It's
okay to unbiasedly randomly select actions. But for more efficient
exploration, it needs to get to unknown (state, action) pairs quickly. 

The authors limit the sensor model to be invertable. I think it's
possible to have a probability version of ASAMI, every function in
this paper is a probability distribution. Then there is no such
limitation.

A general question about function approximation - can the degree of
the polynomial only be pre-selected?

Is W_a(t), the state estimation based on action model, really
incremental?  It's the sum of $A$, the action model, on every (state,
action) pair in the history. In every step $A$ is updated, should the
sum be re-calculated? Because it employs function approximation, $A$
would change globaly responding to local update.

The adverse effect the authors described in page 15 is very
interesting. If I understand correctly, it is because the update of
action model and the change of state are observed in one step. The
previous change of $A$ affects w_s, which in turn affects new $A$.

"If the learning process starts with uninitialized models, it is
likely to lead to meaningless, possibly deceptive models." (page 16,
line 1 below caption of figure)
I have a concern about the correctness of ASAMI. So this is unlike
Q-learning, which can tolerate unitialized models. What's the
constraints of $A_0$ to guarantee the correctness of the models?

I think this idea can be generalized to any robot with transition and
observation model, not necessary restricted to mobile ones.

== Summary ==

*. Learning and Using Models of Kicking Motions for Legged Robots 



*. Towards Autonomous Sensor and Actuator Model Induction on a Mobile
Robot




