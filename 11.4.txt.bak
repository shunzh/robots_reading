Name: Shun Zhang
EID: sz4554

== Comments and Questions ==

*. Intelligence without Representation

The author uses the example of evolution of intelligence on the earth.
However, that is more likely to be an *uncouscious process*. While AI
is a kind of *intelligent design*. We do make intelligent agent much
faster than the earth did.

I think abstraction is necessary. The author seems not to completely
disagree on abstraction. When we want to solve a problem that
generally apply to many concrete problems, we do need abstraction.

I don't think the man, chair and banana example is a good one. It's
possible that a child also employes something like first-order
representation, like HUNGERY + FOOD -> -HUNGERY, BANANA is FOOD, CHAIR
is SUSTAINABLE. A child who has not known any of these facts still
cannot come up with a plan.

It's a good point that we shouldn't always provide the robot with our
introspection to the world. But it's okay if we want to make something
human-like.

The author's definition on Creature actually means fully autonomous
agent.

About the model described in Figure 2,
- It's not probabilistic, so I don't know whether this model is fully
  tested and can be absolutely correct. It could have a more flexible
  model behind it (then this figure is the "policy function" of it).
  Then it will still have the representation.
- It can explore, but with very limited capcity. It can have knowledge
  other than new places but cannot be represented here.

Actually I still have a hard time understanding how they could
eliminate representation totally. This was published quite early. Was
there any progress in this direction in AI?

*. Experiences with an Architecture for Intelligent, Reactive Agents

This architecture is fine. However, is this an essential problem? It
doesn't help to solve any problem in robotics. This serves as a
suggestion on code organization level.

I think our codebase is similar to this architecture. We have state
machines, matching sequencer, in which each state calls lower level
actions, matching skill manager. We manually make the agenda, instead
of using a higher level goal.

== Summary ==

*. Intelligence without Representation

The author argues that abstraction is dangerous as it simplifies the
problem and ignores the part that could be hard to solve.

The author suggests that an autonomous agent should not have a
central control, or even a central representation. It has different
layers of behaviors, one based on another, without explicit
representation of the model of the world. It exposes itself to the
world and uses world as a model.

*. Experiences with an Architecture for Intelligent, Reactive Agents

The authors suggest that the organization of robots should be devided
into planner, sequencer and skill manager. Like OOP, this encapsulates
each module.
